{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# ## prepare the original data\n",
    "# with tf.name_scope('data'):\n",
    "#     x_data = np.random.rand(100).astype(np.float32)\n",
    "#     y_data = 0.3*x_data+0.1\n",
    "# ##creat parameters\n",
    "# with tf.name_scope('parameters'):\n",
    "#     with tf.name_scope('weights'):\n",
    "#         weight = tf.Variable(tf.random_uniform([1],-1.0,1.0))\n",
    "#         tf.summary.histogram('weight',weight)\n",
    "#         with tf.name_scope('biases'):\n",
    "#             bias = tf.Variable(tf.zeros([1]))\n",
    "#             tf.summary.histogram('bias',bias)\n",
    "# ##get y_prediction\n",
    "# with tf.name_scope('y_prediction'):\n",
    "#     y_prediction = weight*x_data+bias\n",
    "# ##compute the loss\n",
    "# with tf.name_scope('loss'):\n",
    "#     loss = tf.reduce_mean(tf.square(y_data-y_prediction))\n",
    "#     tf.summary.scalar('loss',loss)\n",
    "# ##creat optimizer\n",
    "# optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "# #creat train ,minimize the loss \n",
    "# with tf.name_scope('train'):\n",
    "#     train = optimizer.minimize(loss)\n",
    "# #creat init\n",
    "# with tf.name_scope('init'): \n",
    "#     init = tf.global_variables_initializer()\n",
    "# ##creat a Session \n",
    "# sess = tf.Session()\n",
    "# #merged\n",
    "# merged = tf.summary.merge_all()\n",
    "# ##initialize\n",
    "# writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "# sess.run(init)\n",
    "# ## Loop\n",
    "# for step  in  range(101):\n",
    "#     sess.run(train)\n",
    "#     rs=sess.run(merged)\n",
    "#     writer.add_summary(rs, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# with tf.name_scope('hidden') as scope:\n",
    "#     a = tf.constant(5, name='alpha')\n",
    "#     W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0), name='weights')\n",
    "#     b = tf.Variable(tf.zeros([1]), name='biases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-  \n",
    "import tensorflow as tf  \n",
    "# 生成一个先入先出队列和一个QueueRunner,生成文件名队列  \n",
    "filenames = ['A.csv']  \n",
    "filename_queue = tf.train.string_input_producer(filenames, shuffle=False)  \n",
    "# 定义Reader  \n",
    "reader = tf.TextLineReader()  \n",
    "key, value = reader.read(filename_queue)  \n",
    "# 定义Decoder  \n",
    "record_defaults = [[1], [1], [1], [1], [1]]  \n",
    "col1, col2, col3, col4, col5 = tf.decode_csv(value,record_defaults=record_defaults)  \n",
    "features = tf.pack([col1, col2, col3])  \n",
    "label = tf.pack([col4,col5])  \n",
    "example_batch, label_batch = tf.train.shuffle_batch([features,label], batch_size=2, capacity=200, min_after_dequeue=100, num_threads=2)  \n",
    "# 运行Graph  \n",
    "with tf.Session() as sess:  \n",
    "    coord = tf.train.Coordinator()  #创建一个协调器，管理线程  \n",
    "    threads = tf.train.start_queue_runners(coord=coord)  #启动QueueRunner, 此时文件名队列已经进队。  \n",
    "    for i in range(10):  \n",
    "        e_val,l_val = sess.run([example_batch, label_batch])  \n",
    "        print e_val,l_val  \n",
    "    coord.request_stop()  \n",
    "    coord.join(threads)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
