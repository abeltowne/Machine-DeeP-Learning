{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.   ,  148.   ,   72.   , ...,    0.   ,   33.6  ,    0.627],\n",
       "       [   1.   ,   85.   ,   66.   , ...,    0.   ,   26.6  ,    0.351],\n",
       "       [   8.   ,  183.   ,   64.   , ...,    0.   ,   23.3  ,    0.672],\n",
       "       ..., \n",
       "       [   5.   ,  121.   ,   72.   , ...,  112.   ,   26.2  ,    0.245],\n",
       "       [   1.   ,  126.   ,   60.   , ...,    0.   ,   30.1  ,    0.349],\n",
       "       [   1.   ,   93.   ,   70.   , ...,    0.   ,   30.4  ,    0.315]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "# url with dataset\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "# download the file\n",
    "raw_data = urllib.request.urlopen(url)\n",
    "# load the CSV file as a numpy matrix\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "# separate the data from the target attributes\n",
    "X = dataset[:,0:7]\n",
    "y = dataset[:,8]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.80      0.86      0.83       500\n",
      "        1.0       0.69      0.60      0.64       268\n",
      "\n",
      "avg / total       0.76      0.77      0.76       768\n",
      "\n",
      "[[429  71]\n",
      " [108 160]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对贝叶斯算法的一点理解\n",
    "### 贝叶斯和逻辑回归对比的不同之处（http://blog.csdn.net/jfhdd/article/details/52319182）\n",
    "### 过滤垃圾邮件和个人阅读广告倾向（https://www.cnblogs.com/hemiy/p/6194710.html#_label0_0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total testing num :150 , naive bayes accuracy :0.960000\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris.data[:5]\n",
    "# #array([[ 5.1,  3.5,  1.4,  0.2],\n",
    "# #       [ 4.9,  3. ,  1.4,  0.2],\n",
    "# #       [ 4.7,  3.2,  1.3,  0.2],\n",
    "# #       [ 4.6,  3.1,  1.5,  0.2],\n",
    "# #       [ 5. ,  3.6,  1.4,  0.2]])\n",
    "\n",
    "#我们假定sepal length, sepal width, petal length, petal width 4个量独立且服从高斯分布，用贝叶斯分类器建模\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    "right_num = (iris.target == y_pred).sum()\n",
    "print(\"Total testing num :%d , naive bayes accuracy :%f\" %(iris.data.shape[0], float(right_num)/iris.data.shape[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
