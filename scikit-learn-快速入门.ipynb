{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载实例数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.   ,  148.   ,   72.   , ...,    0.   ,   33.6  ,    0.627],\n",
       "       [   1.   ,   85.   ,   66.   , ...,    0.   ,   26.6  ,    0.351],\n",
       "       [   8.   ,  183.   ,   64.   , ...,    0.   ,   23.3  ,    0.672],\n",
       "       ..., \n",
       "       [   5.   ,  121.   ,   72.   , ...,  112.   ,   26.2  ,    0.245],\n",
       "       [   1.   ,  126.   ,   60.   , ...,    0.   ,   30.1  ,    0.349],\n",
       "       [   1.   ,   93.   ,   70.   , ...,    0.   ,   30.4  ,    0.315]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "# url with dataset\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "# download the file\n",
    "raw_data = urllib.request.urlopen(url)\n",
    "# load the CSV file as a numpy matrix\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "# separate the data from the target attributes\n",
    "X = dataset[:,0:7]\n",
    "y = dataset[:,8]\n",
    "X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03494617,  0.86200564,  0.41935409, ...,  0.        ,\n",
       "         0.19569858,  0.00365188],\n",
       "       [ 0.00872683,  0.74178025,  0.57597054, ...,  0.        ,\n",
       "         0.23213358,  0.00306312],\n",
       "       [ 0.04093566,  0.93640332,  0.32748532, ...,  0.        ,\n",
       "         0.11922512,  0.0034386 ],\n",
       "       ..., \n",
       "       [ 0.02727338,  0.66001582,  0.39273669, ...,  0.61092373,\n",
       "         0.14291252,  0.0013364 ],\n",
       "       [ 0.0070043 ,  0.8825414 ,  0.42025781, ...,  0.        ,\n",
       "         0.21082934,  0.0024445 ],\n",
       "       [ 0.00804902,  0.74855891,  0.56343144, ...,  0.        ,\n",
       "         0.24469022,  0.00253544]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# normalize the data attributes\n",
    "normalized_X = preprocessing.normalize(X)\n",
    "# standardize the data attributes\n",
    "standardized_X = preprocessing.scale(X)\n",
    "normalized_X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征的选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13021495  0.26037193  0.11960457  0.09117502  0.08822158  0.16829358\n",
      "  0.14211838]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, y)\n",
    "# display the relative importance of each attribute\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False False False  True  True]\n",
      "[1 2 3 5 4 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "rfe = RFE(model, 3)\n",
    "rfe = rfe.fit(X, y)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.89      0.84       500\n",
      "        1.0       0.74      0.55      0.63       268\n",
      "\n",
      "avg / total       0.77      0.77      0.77       768\n",
      "\n",
      "[[447  53]\n",
      " [120 148]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y\n",
    "predicted = model.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
